# huawei_codecraft2018
huawei codecraft 2018 

this is the summary of my first huawei codecraft competition.
2018 华为软件精英挑战赛总结

赛题[传送门](http://codecraft.devcloud.huaweicloud.com/home/detail)

<!--more-->

该题主要分成相对独立的两个步骤：

1. 时间序列预测
2. 装箱问题

预测部分，题目给出一系列历史时间的虚拟机请求数据，包括请求时间和虚拟机规格。根据历史数据，预测紧接着后一周的每种类型的虚拟机的请求数量。预测出数量后，把这些虚拟机全部部署在一系列的宿主机上，宿主机资源不能超分，所有的虚拟机都要放置。

如果组队合适的话三个人分工合作也许会更容易出成绩，我自己是单独一个组队参赛的，所以很累，最后成绩并不是很理想，高级用例得分偏低，没有进复赛，现在反思一下自己的思路和方法顺便学习一波高排名选手的优秀解决方案。

---

预测部分参考了成渝区的瓜皮战队，具体见[知乎](https://www.zhihu.com/question/268448695)。接下来总结一下我没有关注或者没有想到的点，也是值得学习的地方。

## 去噪

关于数据去噪，又叫数据预处理，是个仁者见仁智者见智的问题，不同的实际场景需要用的方法不一样，没有一招鲜吃遍天的说法。该团队的队员认为粗去噪比精去噪要好，因为去噪去的不好反而可能达到南辕北辙的效果，不如不去。该队主要提出了两个去噪方法。

### 箱型图去噪法

先将数据进行排序，找到位于四分之一位置和四分之三位置的数值，两者相减得到一个IQR，然后设置常数值ｋ=3, 将数据中大于\[3/4位置＋k\*IQR\]与小于\[1/4位置-k\*IQR\]的视为噪点，将其记下来，返回到未排序的原始序列中去掉，然后用其他值填补，怎么填补就见仁见智了，可以多尝试下。

下面的是python实现的检测异常值的算法。

```python
def detectoutliers(data:list):
    """箱型图检测异常值"""
    data = data.tolist()
    outlier_list_col = []
    # Q1为数据占25%的数据值范围
    Q1 = np.percentile(data, 25)
    # Q3为数据占75%的数据范围
    Q3 = np.percentile(data, 75)
    IQR = Q3 - Q1
    #异常值的范围
    outlier_step = 1.5 * IQR
    for n in range(len(data)):
        if float(data[n]) < Q1 - outlier_step or float(data[n]) > Q3 + outlier_step:
            outlier_list_col.append(data[n])
    # print(outlier_list_col)
    return outlier_list_col
```
但是上述方法对于该题的数据有着明显的缺陷。通过绘制数据点，发现数据中有大量的０值，用上述方法将０值全部剔除无疑将是灾难性的后果，瓜皮团队对上述方法的两点改进：

* 可以只用剔除异常的上届，而不用去除箱型图中的下届。
* 自适应的IQR自适应的IQR，可以考虑一下，如果某个flavor有大量的相同点，比如在大部分天数上用量都为3，那么你找到的1/4和3/4位置的值就都会为3，两者相减IQR等于0，去噪的时候就会把所有大于3的点全部去掉，这也是不科学的。所以算IQR的时候可以判定一下IQR是否为零，如果为零那么就将3/4位置往后推一位（比如说当前数据一共有40天，3/4位置为第30天，如果此时算出来的IQR为0，那么就将3/4位置往后推一位变成第31天），重新计算IQR，如果还为0就继续推直到找到可以使IQR不为0的点（注意一下越界的处理），最后用这个不为0的IQR去去掉大于上界的值。

箱型图可以说是一个十分稳定的算法，箱型图需要的参数不多，至多就调整一下K的值与如何填补噪点（3和1.5都是可选的数值，个人推荐3）。有些同学我给他们介绍箱型图后他们选择了对箱型图的K进行调整，比如将K调的特别大或者特别小，虽然最后上分了，但我不推荐这种做法，因为过分的调整K值等于是在调参，本来预测部分参数就多这样等于是强行加了一个参数，容易过拟合（有一个队好像就是因为这样导致过拟合严重最后分数过低），而3这个值是前人通过经验得出的（大概还有理论支撑？），最好别动。

## 预测

关于预测这一块，比较重要的一点就是选取一个模型，一个简单易用而且符合本次数据的模型才是提分的关键。不知道大家有没有听过机器学习中的没有免费的午餐这一定理没有（周志华的西瓜书中貌似有提过），就是说对于任意给定数据集而言两种算法表现为好的可能性都是一样的，具体的定理内容可以百度一下，比我讲的详细。简而言之就是从本质上来就没有最好的模型一说，只有针对数据集选取合适的模型并把它用好才是真理，甚至有时候不要拘泥于选取合适的模型，就算是只忠于一个模型只要你把它用好了那么它就是最合适的模型。      

针对短期预测模型，我队用的比较好的有线性回归和指数平滑，在和其他队伍交流的时候有的队有用过arima等模型，一一讨论。

1.线性回归   
   
线性模型可以说是最简单也是最实用的模型了。做机器学习类的问题，在不清楚数据具体特性的时候，一般会先上线性模型，主要是出于以下考量，一个是它是一个基础模型，你基本不会在上面取得很差的结果，所以可以作为一个保底模型或者说作为一个对比模型；另一个是它可以用来测试特征的有效性，根据之前说的，如果你选好了特征，在任何一个模型上其实都能取得一个不错的效果，如果一些特征在线性上加了之后都不会取得很好的效果那么你基本可以断定在别的模型上也不会取得很好的效果（当然无绝对）。特别是当我们把比赛数据可视化了之后可以发现数据的走势基本上没有规律，所以这时候用线性其实上是最好的。所以先上线性，通过线性这个简单的模型来筛选特征，当做到了极致之后换一个针对本次比赛拟合的更好的模型进行锦上添花。    

在线性模型的特征选取上我队选用的是天特征，简单来讲就是把靠近预测天数的35天数据提取出来，用一条线去拟合这35天的走势，拟合出来的这一条线到这35个点的欧式距离为平面上所有的线到这35个点的欧式距离最小，然后用拟合出来的线去预测。预测的时候找出这条线之后一直往前延伸，一直延伸到你要预测的日期终点，然后把预测出来的值加到一起就是你要预测的总量了。对于选取这个点好像是个玄学，不过我经过测试后发现当选取的点是7的倍数诸如35，28，21的时候都要比不是7的倍数的预测结果要好，可能是因为数据在七天七天之中有一种冥冥的规律。在训练这条线的时候，我队是用感知机的训练方式去训练的，由于只是一条线，其实训练次数不用太多100次迭代足以，学习率设为1即可。哦对了，输入输出数据记得归一化，不然计算量可能会爆掉。 

在特征选取这一块，除了每一天的特征，还可以加上前一天的特征，星期特征或者一周的总用量等等特征，不过经过我们的大量实践后发现，加了之后基本等于没加，一个简单的当天的flavor用量足以。     

由于所有用于训练的点对线性回归这条线的贡献都是一样的，所以线性回归能比较准确的把握住数据整体的趋势（比如向上或者向下），无论你用线性回归预测长期的数据还是短期的数据，误差的期望其实是一致的。 

2.指数平滑      

指数平滑的推导还有公式网上都有，我就不推导了。根据我的个人理解，一次指数平滑适用于平滑数据，二次指数平滑适用于有一定向上或者向下走向的数据，三次指数平滑适用于有一定走向且呈现出周期性规律的数据。将数据可视化后可以发现，数据一不具有平稳性（甚至可以说跳动非常大），二不具有周期性（波峰波谷出现的毫无规律），但是起伏还是具有的，所以宜采用二次指数平滑。我这里采用的二次指数平滑是单参数版本的二次指数平滑，复赛阶段alpha设为0.2效果最好。   

这里多说一点，由于指数平滑的特性也就是离预测点越近的数据权重越大，所以决定了在使用二次指数平滑的时候最好只往前预测一个，而如果要继续向前预测也就是预测第二个的时候由于误差的累积会导致第二个的误差放大，而不会像线性回归那样第一个点和第二个点的误差期望基本一致。基于这一情况考虑，建议把数据七天七天的sum起来然后再用指数平滑而不是对一天天的数据用线性回归，而且七天七天的数据sum也符合一个星期有七天这一冥冥中的规律，尽最大的可能的去预测多天的用量而不产生太大的误差。      

在使用二次指数平滑的时候有两种用法，一种用法是算出at与bt然后根据（at+bt*T）这个公式依次算出接下来的预测值，还有一种是算出一个预测值之后append到数据的后面重新做一次指数平滑然后再预测出下一个。两种算法从理论上孰优孰劣暂且不讨论（我也搞不懂啊），不过在目前比赛的实践下我发现，两者好像都挺差的，把数据七天七天的sum起来然后用指数平滑预测出第一个其实就已经完成指数平滑的使命了，再往下预测接下来的效果就差强人意了，至于剩下的其实可以用别的在长期预测上表现的好的模型（后面会讨论）。 
     
3.移动平均      

好像是叫这个名词吧？直观来讲就是在本次比赛中大家耳熟能详的平均数大法，做法很简单，就是将临近预测前N天（10天？）的数据加到一起然后求个平均数，要预测多少天就乘以多少天，如果效果不好，那就乘以一个修正系数。别看简单，这个方法还是有理论支撑的！网上可以找到相关的文献。对付这种杂乱无章而且让人毫无头绪的数据，其实有时候平均数才是性价比最高的模型，有很多队伍就用了这个模型进了复赛乃至进了决赛。这个恰巧也验证了我前边的说法，模型没有好坏之分，如果你用对了，那就是最好的。为什么有些人能靠平均数进决赛呢？无它，只是因为他们恰巧抓住了最主要的特征（虽然我并不觉得他们发现自己抓住了）并且用对了。（好吧，我都不敢想象如果即抓对了特征又抓住了模型，那预测这一块到底会有多恐怖，大部分人在特征和模型这一块只抓住了一个，而平均数告诉了我们抓住特征比抓住模型更重要） 

4.其他模型      

当然我们也用了一些其他的模型比如arima，局部线性回归等模型，可能是因为用的不对所以效果并不拔群。不过我觉得这个比赛完全不需要用到太复杂的模型，采用太复杂的模型还会在使用上带来一定的困难和维护上的不方便，简单模型一来实现方便，二来可以很清楚的定位到问题出在哪里，用得好才是第一要素。      

5.模型的融合      

模型的融合可以说是一块很大的内容，很难把握住其要点，我这里主要说一下我队进行模型融合的一些小技巧。我队对用模型融合的使用主要集中在取长补短这一方面展开，具体举一个例子吧，比如说复赛的时候大部分都会发现初级用例的gap为0，预测天数为7，而我在对比后发现二次指数平滑在初级用例上能打35.6分，而线性回归最高能打28分，而当预测天数拉长的时候也就是到了中级用例这一块的时候，二次指数平滑的效果就会急速下降而线性回归模型表现依然稳定，这从一个侧面说明了二次指数平滑适用于短期的预测，而线性回归在长期预测这一块表现会更好一点。所以我们在预测的时候，会先用二次指数平滑预测出头七天的用量，而剩下天数的预测用量交给线性回归去预测，从而说达到一个简单的模型融合吧。
